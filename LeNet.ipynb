{"cells":[{"outputs":[],"execution_count":null,"source":"# 查看当前挂载的数据集目录\n!ls /home/kesci/input/","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"CDE36D51DCE647F78B40E9253CC03B28"}},{"outputs":[],"execution_count":null,"source":"# 查看个人持久化工作区文件\n!ls /home/kesci/work/","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"7D3E05FFBB764803ACFA0CB022E713D5"}},{"outputs":[],"execution_count":null,"source":"# 查看当前kernerl下的package\n!pip list --format=columns","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"FD9CEA319E924CAC9936BD2F617629E0"}},{"outputs":[],"execution_count":null,"source":"# 显示cell运行时长\n%load_ext klab-autotime","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"EDA81D5E19F74B6C8260615C81A0458B"}},{"metadata":{"id":"27AB39BE138E48E788B6E286797A2EFC","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#import\nimport sys\nsys.path.append(\"/home/kesci/input\")\nimport d2lzh1981 as d2l\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport time","execution_count":12},{"metadata":{"id":"0121EF2513A84CDF86EF9792A7153B42","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Reshape output shape: \t torch.Size([1, 1, 28, 28])\nConv2d output shape: \t torch.Size([1, 6, 28, 28])\nSigmoid output shape: \t torch.Size([1, 6, 28, 28])\nAvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\nConv2d output shape: \t torch.Size([1, 16, 10, 10])\nSigmoid output shape: \t torch.Size([1, 16, 10, 10])\nAvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\nFlatten output shape: \t torch.Size([1, 400])\nLinear output shape: \t torch.Size([1, 120])\nSigmoid output shape: \t torch.Size([1, 120])\nLinear output shape: \t torch.Size([1, 84])\nSigmoid output shape: \t torch.Size([1, 84])\nLinear output shape: \t torch.Size([1, 10])\n","name":"stdout"}],"source":"class Flatten(torch.nn.Module):\n    def forward(self, x):\n        return x.view(x.shape[0], -1)\n\nclass Reshape(torch.nn.Module):\n    def forward(self, x):\n        return x.view(-1,1,28,28)\n    \nLeNet = torch.nn.Sequential(                                                \n    Reshape(),\n    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n    nn.Sigmoid(),                                                       \n    nn.AvgPool2d(kernel_size=2, stride=2),                              \n    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),           \n    nn.Sigmoid(),\n    nn.AvgPool2d(kernel_size=2, stride=2),                              \n    Flatten(),                                                          \n    nn.Linear(in_features=16*5*5, out_features=120),\n    nn.Sigmoid(),\n    nn.Linear(120, 84),\n    nn.Sigmoid(),\n    nn.Linear(84, 10)\n)\nX = torch.randn(size=(1,1,28,28), dtype = torch.float32)\nfor layer in LeNet:\n    X = layer(X)\n    print(layer.__class__.__name__,'output shape: \\t',X.shape)","execution_count":13},{"metadata":{"id":"8259FD0E9AF647B288F4D61C63017659","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"Sequential(\n  (0): Reshape()\n  (1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (2): Sigmoid()\n  (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (5): Sigmoid()\n  (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (7): Flatten()\n  (8): Linear(in_features=400, out_features=120, bias=True)\n  (9): Sigmoid()\n  (10): Linear(in_features=120, out_features=84, bias=True)\n  (11): Sigmoid()\n  (12): Linear(in_features=84, out_features=10, bias=True)\n)"},"transient":{}}],"source":"# net中参数有默认初始化，这里自定义初始化参数\ndef init_weights(m):\n    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n        torch.nn.init.xavier_uniform_(m.weight)\nLeNet.apply(init_weights)","execution_count":14},{"metadata":{"id":"EEB6DC277C5749FA816EFEEA44BADEC2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"batch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(\n    batch_size=batch_size, root='/home/kesci/input/FashionMNIST2065')","execution_count":15},{"metadata":{"id":"04639C36DDDD4D20939CC83B3CC5AB8A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if torch.cuda.is_available():\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')","execution_count":16},{"metadata":{"id":"CF4F57A71248413081736FF6BA65274F","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"epoch 1, loss 0.0544, train acc 0.603, test acc 0.100\nepoch 2, loss 0.0519, train acc 0.957, test acc 0.387\nepoch 3, loss 0.0266, train acc 3.338, test acc 0.642\nepoch 4, loss 0.0204, train acc 3.951, test acc 0.624\nepoch 5, loss 0.0180, train acc 4.212, test acc 0.699\n","name":"stdout"}],"source":"num_epochs = 5\nLeNet.to(device)\n\nloss = nn.CrossEntropyLoss()\noptimizer = optim.SGD(LeNet.parameters(), lr=0.5)\n\nfor epoch in range(num_epochs):\n    train_l_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n    train_acc_sum = torch.tensor([0.0], dtype=torch.float32, device=device)\n    n = 0\n    for X, y in train_iter:\n        # train model\n        LeNet.train()\n        optimizer.zero_grad()\n        X, y = X.to(device), y.to(device)\n        y_hat = LeNet(X)\n        l = loss(y_hat, y)\n        l.backward()\n        optimizer.step()\n        \n        with torch.no_grad():\n            train_l_sum += l\n            train_acc_sum += torch.sum(torch.argmax(y_hat, dim=1) == y)\n            n += y.shape[0]\n    acc_sum, n = torch.tensor([0], dtype=torch.float32, device=device), 0\n    for X, y in test_iter:\n        # eval model\n        LeNet.eval()\n        X, y = X.to(device), y.to(device)\n        with torch.no_grad():\n            y = y.long()\n            acc_sum += torch.sum((torch.argmax(LeNet(X), dim=1) == y))\n            n += y.shape[0]\n    test_acc = acc_sum.item() / n\n    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n              % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc))","execution_count":17},{"metadata":{"id":"013DDC719F6141F188B233A0F699C988","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"test loss:  0.0029852605819702146\ntest acc:  0.6994\n","name":"stdout"}],"source":"#test\nacc_sum = 0\nl_sum = 0\nn = 0\nfor data, label in test_iter:\n    data, label = data.to(device), label.to(device)\n    # eval model\n    LeNet.eval()\n    y_pre = LeNet(data)\n    acc_sum += torch.sum((torch.argmax(y_pre, dim=1) == label))\n    l_sum += loss(y_pre, label)\n    n += label.shape[0]\nprint('test loss: ', l_sum.item() / n)\nprint('test acc: ', acc_sum.item() / n)","execution_count":30},{"metadata":{"id":"CBD18D02588241ADA412F4AFBBCD037C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}